{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/34547/logos/header.png?t=2022-02-15-22-37-27\" width=1500 class=\"center\">\n","<h1 align=\"center\">ü•• How To Create a COCO Dataset ü••</h1>\n","<h1 align=\"center\" style=\"background-color:#D4FFC8\">PLEASE UPVOTE IF YOU LIKED! üôèüèº</h1>\n","\n","Checkout the [dataset here](https://www.kaggle.com/datasets/alejopaullier/hubmap-hpa-coco-dataset)\n","\n","The objective of this notebook is to create a [COCO format](https://cocodataset.org/#format-data) dataset given a `.csv` file which contains image metadata such as image IDs, segmentations, paths to images, etc, and a folder containing the images.\n","\n","**With some little changes this notebook can be adapted to a different problem.**\n","\n","In this notebook we will:\n","- Define functions to decode and encode RLE strings.\n","- Define a function to create a COCO dataset.\n","- Transform our data and save it.\n","- Visualize some examples to check quality.\n","\n","This notebook was inspired by [Cocoformat dataset creation Instance Segmentation](https://www.kaggle.com/code/mohanrobotics/cocoformat-dataset-creation-instance-segmentation/notebook).\n","\n","Hope you like it! ‚ö°Ô∏è\n","\n","<p style=\"background-color:#FFCBCB; color:Red\">Note: I don't know why but RLE masks need to be transposed. If you know the reason please leave it in the comments.</p>"]},{"cell_type":"markdown","metadata":{},"source":["### Import libraries üìö"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:18.23766Z","iopub.status.busy":"2022-07-15T23:53:18.236827Z","iopub.status.idle":"2022-07-15T23:53:20.002742Z","shell.execute_reply":"2022-07-15T23:53:20.001604Z","shell.execute_reply.started":"2022-07-15T23:53:18.237618Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import itertools\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","\n","\n","from itertools import groupby\n","from skimage import io\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["### Install pycocotools ü••üõ†"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:20.00547Z","iopub.status.busy":"2022-07-15T23:53:20.00504Z","iopub.status.idle":"2022-07-15T23:53:54.758526Z","shell.execute_reply":"2022-07-15T23:53:54.757412Z","shell.execute_reply.started":"2022-07-15T23:53:20.005429Z"},"trusted":true},"outputs":[],"source":["#!pip3 install pycocotools\n","import pycocotools.mask as mask_util"]},{"cell_type":"markdown","metadata":{},"source":["### Functions üìú"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:54.760602Z","iopub.status.busy":"2022-07-15T23:53:54.76027Z","iopub.status.idle":"2022-07-15T23:53:54.783331Z","shell.execute_reply":"2022-07-15T23:53:54.781995Z","shell.execute_reply.started":"2022-07-15T23:53:54.760568Z"},"trusted":true},"outputs":[],"source":["def rle_decode(mask_rle, shape):\n","    \"\"\"\n","    Decodes run-length encoded segmentation mask string into 2d array\n","\n","    Parameters\n","    ----------\n","    :param rle_mask (str): Run-length encoded segmentation mask string.\n","    :param shape (tuple): (height, width) of array to return\n","    :return mask [numpy.ndarray of shape (height, width)]: Decoded 2d segmentation mask\n","    \"\"\"\n","    # Splits the RLE string into a list of string by whitespaces.\n","    s = mask_rle.split()\n","    \n","    # This creates two numpy arrays, one with the RLE starts and one with their respective lengths\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    \n","    # To obtain the end point we need to substract 1 to the length or start because the initial point counts.\n","    starts -= 1\n","    ends = starts + lengths\n","    \n","    # Create a 1D array of size H*W of zeros\n","    mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    \n","    # Fill this array with ones in the positions where there is a mask using the RLE information\n","    for start, end in zip(starts, ends):\n","        mask[start:end] = 1\n","    \n","    # Reshape the 1D array into a 2D array so we can finally get the binary 2D mask.\n","    mask = mask.reshape(shape)\n","    return mask.T\n","\n","\n","def binary_mask_to_rle(binary_mask):\n","    \"\"\"\n","    Checkout: https://cocodataset.org/#format-results\n","    :param mask [numpy.ndarray of shape (height, width)]: Decoded 2d segmentation mask\n","    \n","    This function returns the following dictionary:\n","    {\n","        \"counts\": encoded mask suggested by the official COCO dataset webpage.\n","        \"size\": the size of the input mask/image\n","    }\n","    \"\"\"\n","    # Create dictionary for the segmentation key in the COCO dataset\n","    rle = {'counts': [], 'size': list(binary_mask.shape)}\n","    # We need to convert it to a Fortran array\n","    binary_mask_fortran = np.asfortranarray(binary_mask)\n","    # Encode the mask as specified by the official COCO format\n","    encoded_mask = mask_util.encode(binary_mask_fortran)\n","    # We must decode the byte encoded string or otherwise we cannot save it as a JSON file\n","    rle[\"counts\"] = encoded_mask[\"counts\"].decode()\n","    return rle\n","\n","\n","def create_coco_format_json(data_frame, classes, filepaths):\n","    \"\"\"\n","    This function creates a COCO dataset.\n","    :param data_frame: pandas dataframe with an \"id\" column.\n","    :param classes: list of strings where each string is a class.\n","    :param filepaths: a list of strings containing all images paths\n","    :return dataset_coco_format: COCO dataset (JSON).\n","    \"\"\"\n","    images = []\n","    annotations = []\n","    categories = []\n","    count = 0\n","    \n","    # Creates a categories list, i.e: [{'id': 0, 'name': 'a'}, {'id': 1, 'name': 'b'}, {'id': 2, 'name': 'c'}] \n","    for idx, class_ in enumerate(classes):\n","        categories.append(\n","            { \n","                \"id\": idx,\n","                \"name\": class_\n","            }\n","        )\n","    \n","    # Iterate over image filepaths\n","    for filepath in tqdm(filepaths):\n","        # Get the image id, e.g: \"10044\"\n","        file_id = filepath.split(\"/\")[-1][:-5]\n","        # Get the image height, e.g: 360 (px)\n","        height = int(data_frame[data_frame[\"id\"]==int(file_id)][\"img_height\"].values[0])\n","        # Get the image width, e.g: 310 (px)\n","        width = int(data_frame[data_frame[\"id\"]==int(file_id)][\"img_width\"].values[0])\n","        # One image has many annotations associated to it (1 for each class), get a list with the indices.\n","        ids = data_frame.index[data_frame['id'] == int(file_id)].tolist()\n","        # Get filename\n","        file_name = filepath.split(\"/\")[-1]\n","        \n","        \n","        if (len(ids) > 0):\n","            # Adding images which has annotations\n","            images.append(\n","                {\n","                    \"id\": file_id,\n","                    \"width\": width,\n","                    \"height\": height,\n","                    \"file_name\": file_name\n","                }\n","            )\n","            for idx in ids:\n","                # Convert the RLE string into a numpy array binary mask\n","                mk = rle_decode(data_frame.iloc[idx]['rle'], (height, width))\n","                ys, xs = np.where(mk)\n","                x1, x2 = min(xs), max(xs)\n","                y1, y2 = min(ys), max(ys)\n","                \"\"\"\n","                Contours can be explained simply as a curve joining all the continuous points (along the boundary),\n","                having same color or intensity. The function retrieves contours from the binary image using the\n","                algorithm specified in the function. One RLE segmentation for a single class may have disconnected\n","                shapes, like \"spots\". We will iterate over these \"spots\" thus creating a new image for each spot.\n","                This image will be temporary, it will help us create annotations for each of these \"spots\".\n","                \"\"\"\n","                contours, hierarchy = cv2.findContours(mk,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n","                \n","                for id_, contour in enumerate(contours):\n","                    # Image with 3 channels where H and W remain the same.\n","                    mask_image = np.zeros((mk.shape[0], mk.shape[1], 3),  np.uint8)\n","                    # This function takes the image and fills the contour inside it.\n","                    cv2.drawContours(mask_image, [contour], -1, (255,255,255), thickness=cv2.FILLED)\n","                    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n","                    mask_image_bool = np.array(mask_image, dtype=bool).astype(np.uint8)\n","                    ys, xs = np.where(mask_image_bool)\n","                    x1, x2 = min(xs), max(xs)\n","                    y1, y2 = min(ys), max(ys)\n","                    enc = binary_mask_to_rle(mask_image_bool)\n","                    seg = {\n","                        'segmentation': enc, \n","                        'bbox': [int(x1), int(y1), int(x2-x1+1), int(y2-y1+1)],\n","                        'area': int(np.sum(mask_image_bool)),\n","                        'image_id':file_id, \n","                        'category_id':classes.index(data_frame.iloc[idx]['organ']), \n","                        'iscrowd':0, \n","                        'id': count\n","                    }\n","                    annotations.append(seg)\n","                    count +=1\n","            \n","    # Create the dataset\n","    dataset_coco_format = {\n","        \"categories\": categories,\n","        \"images\": images,\n","        \"annotations\": annotations,\n","    }\n","    \n","    return dataset_coco_format\n","\n","\n","def sep():\n","    print(\"-\"*100)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["### Load data üíæ"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:54.787007Z","iopub.status.busy":"2022-07-15T23:53:54.786595Z","iopub.status.idle":"2022-07-15T23:53:55.154634Z","shell.execute_reply":"2022-07-15T23:53:55.153486Z","shell.execute_reply.started":"2022-07-15T23:53:54.786972Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>organ</th>\n","      <th>data_source</th>\n","      <th>img_height</th>\n","      <th>img_width</th>\n","      <th>pixel_size</th>\n","      <th>tissue_thickness</th>\n","      <th>rle</th>\n","      <th>age</th>\n","      <th>sex</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10044</td>\n","      <td>prostate</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n","      <td>37.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10274</td>\n","      <td>prostate</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n","      <td>76.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10392</td>\n","      <td>spleen</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n","      <td>82.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10488</td>\n","      <td>lung</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n","      <td>78.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10610</td>\n","      <td>spleen</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n","      <td>21.0</td>\n","      <td>Female</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id     organ data_source  img_height  img_width  pixel_size  \\\n","0  10044  prostate         HPA        3000       3000         0.4   \n","1  10274  prostate         HPA        3000       3000         0.4   \n","2  10392    spleen         HPA        3000       3000         0.4   \n","3  10488      lung         HPA        3000       3000         0.4   \n","4  10610    spleen         HPA        3000       3000         0.4   \n","\n","   tissue_thickness                                                rle   age  \\\n","0                 4  1459676 77 1462675 82 1465674 87 1468673 92 14...  37.0   \n","1                 4  715707 2 718705 8 721703 11 724701 18 727692 3...  76.0   \n","2                 4  1228631 20 1231629 24 1234624 40 1237623 47 12...  82.0   \n","3                 4  3446519 15 3449517 17 3452514 20 3455510 24 34...  78.0   \n","4                 4  478925 68 481909 87 484893 105 487863 154 4908...  21.0   \n","\n","      sex  \n","0    Male  \n","1    Male  \n","2    Male  \n","3    Male  \n","4  Female  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>organ</th>\n","      <th>data_source</th>\n","      <th>img_height</th>\n","      <th>img_width</th>\n","      <th>pixel_size</th>\n","      <th>tissue_thickness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10078</td>\n","      <td>spleen</td>\n","      <td>Hubmap</td>\n","      <td>2023</td>\n","      <td>2023</td>\n","      <td>0.4945</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id   organ data_source  img_height  img_width  pixel_size  \\\n","0  10078  spleen      Hubmap        2023       2023      0.4945   \n","\n","   tissue_thickness  \n","0                 4  "]},"metadata":{},"output_type":"display_data"}],"source":["# Setting the paths.\n","DATASET_PATH = \"/Users/jiehyun/kaggle/input/hubmap-organ-segmentation/\"\n","IMAGE_DIR = DATASET_PATH + \"train_images/\"\n","TRAIN_CSV_PATH = DATASET_PATH + \"train.csv\"\n","TEST_CSV_PATH = DATASET_PATH + \"test.csv\"\n","\n","# Creating a dataframe.\n","train_df = pd.read_csv(TRAIN_CSV_PATH, sep=',')\n","test_df = pd.read_csv(TEST_CSV_PATH, sep=',')\n","display(train_df.head())\n","sep()\n","display(test_df.head())"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:55.156192Z","iopub.status.busy":"2022-07-15T23:53:55.155861Z","iopub.status.idle":"2022-07-15T23:53:55.185895Z","shell.execute_reply":"2022-07-15T23:53:55.184896Z","shell.execute_reply.started":"2022-07-15T23:53:55.156164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Train Images:351\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>organ</th>\n","      <th>data_source</th>\n","      <th>img_height</th>\n","      <th>img_width</th>\n","      <th>pixel_size</th>\n","      <th>tissue_thickness</th>\n","      <th>rle</th>\n","      <th>age</th>\n","      <th>sex</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10044</td>\n","      <td>prostate</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n","      <td>37.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10274</td>\n","      <td>prostate</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n","      <td>76.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10392</td>\n","      <td>spleen</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n","      <td>82.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10488</td>\n","      <td>lung</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n","      <td>78.0</td>\n","      <td>Male</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10610</td>\n","      <td>spleen</td>\n","      <td>HPA</td>\n","      <td>3000</td>\n","      <td>3000</td>\n","      <td>0.4</td>\n","      <td>4</td>\n","      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n","      <td>21.0</td>\n","      <td>Female</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id     organ data_source  img_height  img_width  pixel_size  \\\n","0  10044  prostate         HPA        3000       3000         0.4   \n","1  10274  prostate         HPA        3000       3000         0.4   \n","2  10392    spleen         HPA        3000       3000         0.4   \n","3  10488      lung         HPA        3000       3000         0.4   \n","4  10610    spleen         HPA        3000       3000         0.4   \n","\n","   tissue_thickness                                                rle   age  \\\n","0                 4  1459676 77 1462675 82 1465674 87 1468673 92 14...  37.0   \n","1                 4  715707 2 718705 8 721703 11 724701 18 727692 3...  76.0   \n","2                 4  1228631 20 1231629 24 1234624 40 1237623 47 12...  82.0   \n","3                 4  3446519 15 3449517 17 3452514 20 3455510 24 34...  78.0   \n","4                 4  478925 68 481909 87 484893 105 487863 154 4908...  21.0   \n","\n","      sex  \n","0    Male  \n","1    Male  \n","2    Male  \n","3    Male  \n","4  Female  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Number of Test Images:1\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>organ</th>\n","      <th>data_source</th>\n","      <th>img_height</th>\n","      <th>img_width</th>\n","      <th>pixel_size</th>\n","      <th>tissue_thickness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10078</td>\n","      <td>spleen</td>\n","      <td>Hubmap</td>\n","      <td>2023</td>\n","      <td>2023</td>\n","      <td>0.4945</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id   organ data_source  img_height  img_width  pixel_size  \\\n","0  10078  spleen      Hubmap        2023       2023      0.4945   \n","\n","   tissue_thickness  \n","0                 4  "]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Number of Train Images:{}\".format(len(train_df)))\n","display(train_df.head())\n","sep()\n","print(\"Number of Test Images:{}\".format(len(test_df)))\n","display(test_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["### Create COCO dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T23:53:55.187612Z","iopub.status.busy":"2022-07-15T23:53:55.187284Z","iopub.status.idle":"2022-07-16T00:08:40.933927Z","shell.execute_reply":"2022-07-16T00:08:40.932647Z","shell.execute_reply.started":"2022-07-15T23:53:55.187581Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/351 [00:00<?, ?it/s]\n"]},{"ename":"IndexError","evalue":"index 0 is out of bounds for axis 0 with size 0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m filepaths_test \u001b[38;5;241m=\u001b[39m [filepaths[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create COCO Datasets\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train_json \u001b[38;5;241m=\u001b[39m create_coco_format_json(train_df, classes, filepaths_train)\n","Cell \u001b[0;32mIn [3], line 82\u001b[0m, in \u001b[0;36mcreate_coco_format_json\u001b[0;34m(data_frame, classes, filepaths)\u001b[0m\n\u001b[1;32m     80\u001b[0m file_id \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Get the image height, e.g: 360 (px)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdata_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Get the image width, e.g: 310 (px)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(data_frame[data_frame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m(file_id)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_width\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n","\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"]}],"source":["# Set classes\n","classes = train_df[\"organ\"].unique().tolist()\n","\n","# Get list with all image file paths\n","filepaths = list()\n","for (dirpath, dirnames, filenames) in os.walk(DATASET_PATH):\n","    filepaths += [os.path.join(dirpath, file) for file in filenames if file.endswith(\".tiff\")]\n","\n","filepaths_train = filepaths[:-1]\n","filepaths_test = [filepaths[-1]]\n","\n","# Create COCO Datasets\n","train_json = create_coco_format_json(train_df, classes, filepaths_train)"]},{"cell_type":"markdown","metadata":{},"source":["### Save results üíª"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-16T00:10:45.745036Z","iopub.status.busy":"2022-07-16T00:10:45.744624Z","iopub.status.idle":"2022-07-16T00:10:45.988043Z","shell.execute_reply":"2022-07-16T00:10:45.98664Z","shell.execute_reply.started":"2022-07-16T00:10:45.745004Z"},"trusted":true},"outputs":[],"source":["with open('train_json.json', 'w', encoding='utf-8') as f:\n","    json.dump(train_json, f, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["### Read COCO Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-16T00:10:46.920023Z","iopub.status.busy":"2022-07-16T00:10:46.918934Z","iopub.status.idle":"2022-07-16T00:10:46.984954Z","shell.execute_reply":"2022-07-16T00:10:46.983739Z","shell.execute_reply.started":"2022-07-16T00:10:46.919979Z"},"trusted":true},"outputs":[],"source":["from pycocotools.coco import COCO\n","\n","gt = COCO(\"./train_json.json\")"]},{"cell_type":"markdown","metadata":{},"source":["# Let's check everything is allright! ‚úÖ"]},{"cell_type":"markdown","metadata":{},"source":["### Plot mask on top of image function\n","\n","Inspired by [AW-Madison: EDA & In Depth Mask Exploration](https://www.kaggle.com/code/andradaolteanu/aw-madison-eda-in-depth-mask-exploration)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-16T00:10:50.353366Z","iopub.status.busy":"2022-07-16T00:10:50.353009Z","iopub.status.idle":"2022-07-16T00:10:50.367575Z","shell.execute_reply":"2022-07-16T00:10:50.366206Z","shell.execute_reply.started":"2022-07-16T00:10:50.353338Z"},"trusted":true},"outputs":[],"source":["from matplotlib.colors import LinearSegmentedColormap\n","from matplotlib.colors import ListedColormap\n","from matplotlib.patches import Rectangle\n","\n","\n","# Custom color map in matplotlib\n","def CustomCmap(rgb_color):\n","\n","    r1,g1,b1 = rgb_color\n","\n","    cdict = {'red': ((0, r1, r1),\n","                   (1, r1, r1)),\n","           'green': ((0, g1, g1),\n","                    (1, g1, g1)),\n","           'blue': ((0, b1, b1),\n","                   (1, b1, b1))}\n","\n","    cmap = LinearSegmentedColormap('custom_cmap', cdict)\n","    return cmap\n","\n","\n","def plot_original_mask(img, mask, alpha=1):\n","\n","    # Change pixels - when 1 make True, when 0 make NA\n","    mask = np.ma.masked_where(mask == 0, mask)\n","\n","    # Plot the 2 images (Original and with Mask)\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n","\n","    # Original\n","    ax1.set_title(\"Original Image\")\n","    ax1.imshow(img)\n","    ax1.axis(\"off\")\n","\n","    # With Mask\n","    ax2.set_title(\"Image with Mask\")\n","    ax2.imshow(img)\n","    ax2.imshow(mask, interpolation='none', cmap=CMAP2, alpha=alpha)\n","#     ax2.legend(legend_colors, labels)\n","    ax2.axis(\"off\")\n","    \n","    plt.show()\n","    \n","\n","def rgb(r,g,b):\n","    return (r/255, g/255, b/255)\n","\n","# --- Custom Color Maps ---\n","# Yellow Purple Red\n","mask_colors = [rgb(232, 0, 255), rgb(0, 4, 255), rgb(0, 251, 255), rgb(0, 255, 15), rgb(247, 255, 0)]\n","legend_colors = [Rectangle((0,0),1,1, color=color) for color in mask_colors]\n","labels = [x.upper() for x in train_df[\"organ\"].unique().tolist()]\n","\n","CMAP1 = CustomCmap(mask_colors[0])\n","CMAP2 = CustomCmap(mask_colors[1])\n","CMAP3 = CustomCmap(mask_colors[2])\n","CMAP4 = CustomCmap(mask_colors[3])\n","CMAP5 = CustomCmap(mask_colors[4])"]},{"cell_type":"markdown","metadata":{},"source":["### Get random image and its mask ü©ª"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-16T00:11:30.471273Z","iopub.status.busy":"2022-07-16T00:11:30.470238Z","iopub.status.idle":"2022-07-16T00:11:34.43752Z","shell.execute_reply":"2022-07-16T00:11:34.436385Z","shell.execute_reply.started":"2022-07-16T00:11:30.471223Z"},"trusted":true},"outputs":[],"source":["def read_tiff(image_path):\n","    image = io.imread(image_path)\n","    return image\n","\n","# Random idx\n","random_image = 4 #np.random.randint(0,len(train_df))\n","# Get image ID\n","img_id = list(gt.imgs)[random_image]\n","# Read image\n","np_image = read_tiff(os.path.join(IMAGE_DIR, gt.imgs[img_id][\"file_name\"]))\n","cv2.imwrite('img.jpg', np_image)\n","img = cv2.imread(\"img.jpg\")\n","\n","for ann_id in gt.getAnnIds(imgIds = [img_id]):\n","    ann_item = gt.anns[ann_id]\n","    mask = mask_util.decode(ann_item[\"segmentation\"])\n","    \n","plot_original_mask(img, mask, alpha=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.4 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"vscode":{"interpreter":{"hash":"5d7dca0821ed5770468f6797715951de7ae209c75d420886d1cf9b2c9327158e"}}},"nbformat":4,"nbformat_minor":4}
