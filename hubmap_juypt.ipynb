{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-30 15:39:54,348 - Created a temporary directory at /var/folders/w2/kjqd2k2x70z1qwx2jy2y7j580000gn/T/tmps6haf1rp\n",
      "2022-09-30 15:39:54,349 - Writing /var/folders/w2/kjqd2k2x70z1qwx2jy2y7j580000gn/T/tmps6haf1rp/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import tifffile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from monai.data import CSVDataset\n",
    "from monai.data import DataLoader\n",
    "from monai.data import ImageReader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_DIR = Path(\"/\") / \"/Users/jiehyun/kaggle\"\n",
    "\n",
    "INPUT_DIR = KAGGLE_DIR / \"input\"\n",
    "OUTPUT_DIR = KAGGLE_DIR / \"working\"\n",
    "\n",
    "COMPETITION_DATA_DIR = INPUT_DIR / \"hubmap-organ-segmentation\"\n",
    "\n",
    "TRAIN_PREPARED_CSV_PATH = \"train_prepared.csv\"\n",
    "VAL_PRED_PREPARED_CSV_PATH = \"val_pred_prepared.csv\"\n",
    "TEST_PREPARED_CSV_PATH = \"test_prepared.csv\"\n",
    "\n",
    "N_SPLITS = 4\n",
    "RANDOM_SEED = 2022\n",
    "SPATIAL_SIZE = 1024\n",
    "VAL_FOLD = 0\n",
    "NUM_WORKERS = 2\n",
    "BATCH_SIZE = 16\n",
    "MODEL = \"unet\"\n",
    "LOSS = \"dice\"\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.0\n",
    "FAST_DEV_RUN = False\n",
    "GPUS = 1\n",
    "MAX_EPOCHS = 10\n",
    "PRECISION = 16\n",
    "DEBUG = False\n",
    "\n",
    "#change it later\n",
    "DEVICE = \"cpu\"\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path_to_df(df: pd.DataFrame, data_dir: Path, type_: str, stage: str) -> pd.DataFrame:\n",
    "    ending = \".tiff\" if type_ == \"image\" else \".npy\"\n",
    "    \n",
    "    dir_ = str(data_dir / f\"{stage}_{type_}s\") if type_ == \"image\" else f\"{stage}_{type_}s\"\n",
    "    df[type_] = dir_ + \"/\" + df[\"id\"].astype(str) + ending\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_paths_to_df(df: pd.DataFrame, data_dir: Path, stage: str) -> pd.DataFrame:\n",
    "    df = add_path_to_df(df, data_dir, \"image\", stage)\n",
    "    df = add_path_to_df(df, data_dir, \"mask\", stage)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_folds(df: pd.DataFrame, n_splits: int, random_seed: int) -> pd.DataFrame:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(X=df, y=df[\"organ\"])):\n",
    "        df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(data_dir: Path, stage: str, n_splits: int, random_seed: int) -> None:\n",
    "    df = pd.read_csv(data_dir / f\"{stage}.csv\")\n",
    "    df = add_paths_to_df(df, data_dir, stage)\n",
    "\n",
    "    if stage == \"train\":\n",
    "        df = create_folds(df, n_splits, random_seed)\n",
    "\n",
    "    filename = f\"{stage}_prepared.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Created {filename} with shape {df.shape}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_prepared.csv with shape (351, 13)\n",
      "Created test_prepared.csv with shape (1, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_data(COMPETITION_DATA_DIR, \"train\", N_SPLITS, RANDOM_SEED)\n",
    "test_df = prepare_data(COMPETITION_DATA_DIR, \"test\", N_SPLITS, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>image</th>\n",
       "      <th>mask</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/10044.npy</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/10274.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/10392.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/10488.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/10610.npy</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>9517</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1611763 11 1614753 29 1617750 35 1620746 43 16...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/9517.npy</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9769</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4030400 28 4033466 34 4036526 48 4039594 54 40...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/9769.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9777</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>538473 13 541468 22 544463 30 547461 35 550459...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/9777.npy</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>9791</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>334733 33 337729 43 340729 43 343725 51 346723...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/9791.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>9904</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1009165 7 1012149 28 1015140 38 1018127 51 102...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>train_masks/9904.npy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           organ data_source  img_height  img_width  pixel_size  \\\n",
       "0    10044        prostate         HPA        3000       3000         0.4   \n",
       "1    10274        prostate         HPA        3000       3000         0.4   \n",
       "2    10392          spleen         HPA        3000       3000         0.4   \n",
       "3    10488            lung         HPA        3000       3000         0.4   \n",
       "4    10610          spleen         HPA        3000       3000         0.4   \n",
       "..     ...             ...         ...         ...        ...         ...   \n",
       "346   9517          kidney         HPA        3000       3000         0.4   \n",
       "347   9769          kidney         HPA        3070       3070         0.4   \n",
       "348   9777  largeintestine         HPA        3000       3000         0.4   \n",
       "349   9791          kidney         HPA        3000       3000         0.4   \n",
       "350   9904  largeintestine         HPA        3000       3000         0.4   \n",
       "\n",
       "     tissue_thickness                                                rle  \\\n",
       "0                   4  1459676 77 1462675 82 1465674 87 1468673 92 14...   \n",
       "1                   4  715707 2 718705 8 721703 11 724701 18 727692 3...   \n",
       "2                   4  1228631 20 1231629 24 1234624 40 1237623 47 12...   \n",
       "3                   4  3446519 15 3449517 17 3452514 20 3455510 24 34...   \n",
       "4                   4  478925 68 481909 87 484893 105 487863 154 4908...   \n",
       "..                ...                                                ...   \n",
       "346                 4  1611763 11 1614753 29 1617750 35 1620746 43 16...   \n",
       "347                 4  4030400 28 4033466 34 4036526 48 4039594 54 40...   \n",
       "348                 4  538473 13 541468 22 544463 30 547461 35 550459...   \n",
       "349                 4  334733 33 337729 43 340729 43 343725 51 346723...   \n",
       "350                 4  1009165 7 1012149 28 1015140 38 1018127 51 102...   \n",
       "\n",
       "      age     sex                                              image  \\\n",
       "0    37.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "1    76.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "2    82.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "3    78.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "4    21.0  Female  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "..    ...     ...                                                ...   \n",
       "346  61.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "347  28.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "348  84.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "349  28.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "350  84.0    Male  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "\n",
       "                      mask  fold  \n",
       "0    train_masks/10044.npy   3.0  \n",
       "1    train_masks/10274.npy   0.0  \n",
       "2    train_masks/10392.npy   0.0  \n",
       "3    train_masks/10488.npy   0.0  \n",
       "4    train_masks/10610.npy   3.0  \n",
       "..                     ...   ...  \n",
       "346   train_masks/9517.npy   2.0  \n",
       "347   train_masks/9769.npy   0.0  \n",
       "348   train_masks/9777.npy   2.0  \n",
       "349   train_masks/9791.npy   0.0  \n",
       "350   train_masks/9904.npy   0.0  \n",
       "\n",
       "[351 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>image</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10078</td>\n",
       "      <td>spleen</td>\n",
       "      <td>Hubmap</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4945</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/jiehyun/kaggle/input/hubmap-organ-segme...</td>\n",
       "      <td>test_masks/10078.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   organ data_source  img_height  img_width  pixel_size  \\\n",
       "0  10078  spleen      Hubmap        2023       2023      0.4945   \n",
       "\n",
       "   tissue_thickness                                              image  \\\n",
       "0                 4  /Users/jiehyun/kaggle/input/hubmap-organ-segme...   \n",
       "\n",
       "                   mask  \n",
       "0  test_masks/10078.npy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(mask_rle: str, shape: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    Source: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "\n",
    "def save_array(file_path: str, array: np.ndarray) -> None:\n",
    "    file_path = Path(file_path)\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(file_path, array)\n",
    "\n",
    "\n",
    "def save_masks(df: pd.DataFrame) -> None:\n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        mask = rle2mask(row.rle, shape=(row.img_width, row.img_height))\n",
    "        save_array(row.mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d13e3232344df39208f54a216ae85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_masks(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "class TIFFImageReader(ImageReader):\n",
    "    def read(self, data: str) -> np.ndarray:\n",
    "        image = tifffile.imread(data)\n",
    "        print(image.shape)\n",
    "        image = rgb2gray(image)\n",
    "        print(image.shape)\n",
    "        return image\n",
    "\n",
    "    def get_data(self, img: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:\n",
    "        return img, {\"spatial_shape\": np.asarray(img.shape), \"original_channel_dim\": -1}\n",
    "\n",
    "    def verify_suffix(self, filename: str) -> bool:\n",
    "        return \".tiff\" in filename\n",
    "\n",
    "class LitDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_csv_path: str,\n",
    "        test_csv_path: str,\n",
    "        spatial_size: int,\n",
    "        val_fold: int,\n",
    "        batch_size: int,\n",
    "        num_workers: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.train_df = pd.read_csv(train_csv_path)\n",
    "        self.test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "        self.train_transform, self.val_transform, self.test_transform = self._init_transforms()\n",
    "        \n",
    "    def _init_transforms(self) -> Tuple[Callable, Callable, Callable]:\n",
    "        spatial_size = (self.hparams.spatial_size, self.hparams.spatial_size)\n",
    "        train_transform = monai.transforms.Compose(\n",
    "            [\n",
    "                monai.transforms.LoadImaged(keys=[\"image\"], reader=TIFFImageReader),\n",
    "                monai.transforms.AddChanneld(keys=[\"image\"]),\n",
    "                monai.transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "                monai.transforms.LoadImaged(keys=[\"mask\"]),\n",
    "                monai.transforms.AddChanneld(keys=[\"mask\"]),\n",
    "                monai.transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=0),\n",
    "                monai.transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=1),\n",
    "                monai.transforms.RandRotate90d(keys=[\"image\", \"mask\"], prob=0.75, spatial_axes=(0, 1)),\n",
    "                monai.transforms.OneOf(\n",
    "                    [\n",
    "                        #monai.transforms.RandGaussianNoised(keys=[\"image\"], prob=1.0, std=0.1),\n",
    "                        monai.transforms.RandAdjustContrastd(keys=[\"image\"], prob=1.0, gamma=(0.5, 4.5)),\n",
    "                        monai.transforms.RandShiftIntensityd(keys=[\"image\"], prob=1.0, offsets=(0.1, 0.2)),\n",
    "                        monai.transforms.RandHistogramShiftd(keys=[\"image\"], prob=1.0),\n",
    "                    ]\n",
    "                ),\n",
    "                monai.transforms.OneOf(\n",
    "                    [\n",
    "                        monai.transforms.RandGridDistortiond(keys=[\"image\", \"mask\"], prob=0.5, distort_limit=0.2),\n",
    "                        #monai.transforms.RandZoomd(keys=[\"image\", \"mask\"], prob=0.5, spatial_size=spatial_size,  mode=\"nearest\"),\n",
    "\n",
    "                    ]\n",
    "                ),\n",
    "                monai.transforms.Resized(keys=[\"image\", \"mask\"], spatial_size=spatial_size, mode=\"nearest\"),\n",
    "                monai.transforms.ToTensord(keys=[\"image\", \"mask\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transform = monai.transforms.Compose(\n",
    "            [\n",
    "                monai.transforms.LoadImaged(keys=[\"image\"], reader=TIFFImageReader),\n",
    "                monai.transforms.AddChanneld(keys=[\"image\"]),\n",
    "                monai.transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "                monai.transforms.LoadImaged(keys=[\"mask\"]),\n",
    "                monai.transforms.AddChanneld(keys=[\"mask\"]),\n",
    "                #monai.transforms.RandZoomd(keys=[\"image\", \"mask\"], prob=0.5, spatial_size=spatial_size,  mode=\"nearest\"),\n",
    "                monai.transforms.Resized(keys=[\"image\", \"mask\"], spatial_size=spatial_size, mode=\"nearest\"),\n",
    "                monai.transforms.ToTensord(keys=[\"image\", \"mask\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        test_transform = monai.transforms.Compose(\n",
    "            [\n",
    "                monai.transforms.LoadImaged(keys=[\"image\"], reader=TIFFImageReader),\n",
    "                monai.transforms.AddChanneld(keys=[\"image\"]),\n",
    "                monai.transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "                monai.transforms.Resized(keys=[\"image\"], spatial_size=spatial_size, mode=\"nearest\"),\n",
    "                monai.transforms.ToTensord(keys=[\"image\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return train_transform, val_transform, test_transform\n",
    "    \n",
    "    def setup(self, stage: str = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_df = self.train_df[self.train_df.fold != self.hparams.val_fold].reset_index(drop=True)\n",
    "            val_df = self.train_df[self.train_df.fold == self.hparams.val_fold].reset_index(drop=True)\n",
    "\n",
    "            self.train_dataset = self._dataset(train_df, transform=self.train_transform)\n",
    "            self.val_dataset = self._dataset(val_df, transform=self.val_transform)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = self._dataset(self.test_df, transform=self.test_transform)\n",
    "\n",
    "    def _dataset(self, df: pd.DataFrame, transform: Callable) -> CSVDataset:\n",
    "        return CSVDataset(src=df, transform=transform)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.train_dataset, train=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.val_dataset)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return self._dataloader(self.test_dataset)\n",
    "\n",
    "    def _dataloader(self, dataset: CSVDataset, train: bool = False) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(title: str, image: np.ndarray, mask: Optional[np.ndarray] = None):\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def show_batch(batch: Dict, nrows: int, show_mask: bool = True):\n",
    "    fig, _ = plt.subplots(figsize=(3 * nrows, 3 * nrows))\n",
    "\n",
    "    for idx, _ in enumerate(batch[\"image\"]):\n",
    "        plt.subplot(nrows, nrows, idx + 1)\n",
    "\n",
    "        title = batch[\"id\"][idx].numpy()\n",
    "        image = np.transpose(batch[\"image\"][idx].numpy(), axes=(1, 2, 0))\n",
    "        mask = np.transpose(batch[\"mask\"][idx].numpy(), axes=(1, 2, 0)) if show_mask else None\n",
    "\n",
    "        show_image(title, image, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiehyun/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "nrows = 1\n",
    "\n",
    "data_module = LitDataModule(\n",
    "    train_csv_path=TRAIN_PREPARED_CSV_PATH,\n",
    "    test_csv_path=TEST_PREPARED_CSV_PATH,\n",
    "    spatial_size=SPATIAL_SIZE,\n",
    "    val_fold=VAL_FOLD,\n",
    "    batch_size=nrows ** 2,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TIFFImageReader' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TIFFImageReader' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 34257, 34258) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 34257) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(data_module\u001b[38;5;241m.\u001b[39mtrain_dataloader()))\n\u001b[1;32m      2\u001b[0m show_batch(train_batch, nrows)\n",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Jenna/UMassBoston/2022_Fall/CS696/02/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 34257, 34258) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "train_batch = next(iter(data_module.train_dataloader()))\n",
    "show_batch(train_batch, nrows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
